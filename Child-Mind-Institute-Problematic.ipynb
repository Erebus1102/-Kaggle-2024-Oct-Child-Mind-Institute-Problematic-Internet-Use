{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2024.10.15 使用Numpy2.0会报错，降级使用Numpy1.24.0可以正常使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Child Mind Institute | SIngleLGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/LLMs/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from copy import deepcopy\n",
    "import optuna\n",
    "from scipy.optimize import minimize\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from colorama import Fore, Style\n",
    "\n",
    "from tqdm import tqdm\n",
    "from IPython.display import clear_output\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:23<00:00, 11.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  7.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 2s, sys: 58.1 s, total: 6min\n",
      "Wall time: 1min 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "def process_file(filename, dirname):\n",
    "    # 使用 os.path.join 函数将目录名、文件名和文件中的 ‘part-0.parquet’ 部分合并，形成一个完整的文件路径。\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet')) \n",
    "    # 从DataFrame df 中删除名为 ‘step’ 的列。axis=1 表示操作是在列的方向上进行的，inplace=True 表示在原DataFrame上进行修改，而不是返回一个新的DataFrame。\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "    \"\"\"\n",
    "    .values.reshape(-1)：将描述性统计的结果转换为一个一维数组。\n",
    "    filename.split('=')[1]：从文件名中提取等号(‘=’)后的部分。这假设文件名格式包含一个等号，并且您想要获取等号后面的部分。\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]：函数返回一个元组，包含描述性统计的一维数组和文件名中特定部分的字符串。\n",
    "    \"\"\"\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname) # 使用 os.listdir 函数获取指定目录 dirname 中的所有文件和目录的名称列表。\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \"\"\"\n",
    "    executor.map(lambda fname: process_file(fname, dirname), ids)：使用 executor.map 方法并行地应用 process_file 函数到 ids 列表中的每个元素上。\n",
    "    这里 lambda 函数是匿名函数，用于将 process_file 函数与参数 dirname 绑定，并将文件名 fname 作为参数传递。\n",
    "    tqdm(..., total=len(ids))：使用 tqdm 包裹 executor.map 调用，显示进度条，其中 total 参数指定了任务的总数，这里是 ids 列表的长度。\n",
    "    \"\"\"\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \"\"\"\n",
    "    results 是一个包含元组的列表，每个元组包含来自 process_file 函数的两个返回值。\n",
    "    使用 zip(*results) 来解包这个列表，并将结果分别赋值给 stats 和 indexes 两个变量。\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(stats, columns=[f\"Stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = pd.read_csv('child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "train_ts = load_time_series(\"child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"child-mind-institute-problematic-internet-use/series_test.parquet\")\n",
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "\n",
    "train = pd.merge(train, train_ts, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts, how=\"left\", on='id')\n",
    "\n",
    "train = train.drop('id', axis=1)\n",
    "test = test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (2736, 155) || Test Shape : (20, 154)\n"
     ]
    }
   ],
   "source": [
    "featuresCols = ['Basic_Demos-Enroll_Season', 'Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-Season', 'CGAS-CGAS_Score', 'Physical-Season', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Season', 'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-Season', 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone', 'BIA-Season',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-Season', 'PAQ_A-PAQ_A_Total', 'PAQ_C-Season',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-Season', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T', 'PreInt_EduHx-Season',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'sii']\n",
    "\n",
    "featuresCols += time_series_cols \n",
    "# 将名为 time_series_cols 的变量添加到 featuresCols 变量的末尾\n",
    "\n",
    "train = train[featuresCols]\n",
    "train = train.dropna(subset='sii')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', 'Fitness_Endurance-Season', \n",
    "          'FGC-Season', 'BIA-Season', 'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']\n",
    "\n",
    "def update(df):\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "        \n",
    "train = update(train)\n",
    "test = update(test)\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "\"\"\"This Mapping Works Fine For me I also Check Each Values in Train and test Using Logic. There no Data Lekage.\"\"\"\n",
    "\n",
    "for col in cat_c:\n",
    "    mapping_train = create_mapping(col, train)\n",
    "    mapping_test = create_mapping(col, test)\n",
    "    \n",
    "    train[col] = train[col].replace(mapping_train).astype(int)\n",
    "    test[col] = test[col].replace(mapping_test).astype(int)\n",
    "\n",
    "print(f'Train Shape : {train.shape} || Test Shape : {test.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLMs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
